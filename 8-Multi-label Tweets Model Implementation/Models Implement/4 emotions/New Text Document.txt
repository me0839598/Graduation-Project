best estimator parameters BinaryRelevance(classifier=GaussianNB(var_smoothing=1e-10),
                require_dense=[True, True])
training data evaluation
hamming score 0.6475577654284879
hamming loss 0.18159549575899386
              precision    recall  f1-score   support

           0       0.64      0.88      0.74      2544
           1       0.68      0.92      0.79      1242
           2       0.70      0.83      0.76      2477
           3       0.62      0.69      0.65      2008

   micro avg       0.66      0.83      0.73      8271
   macro avg       0.66      0.83      0.74      8271
weighted avg       0.66      0.83      0.73      8271
 samples avg       0.68      0.76      0.69      8271

development data evaluation
hamming score 0.543359668924003
hamming loss 0.22545146726862303
              precision    recall  f1-score   support

           0       0.63      0.66      0.64       315
           1       0.58      0.31      0.41       121
           2       0.75      0.76      0.75       400
           3       0.53      0.19      0.28       265

   micro avg       0.67      0.54      0.60      1101
   macro avg       0.62      0.48      0.52      1101
weighted avg       0.64      0.54      0.57      1101
 samples avg       0.61      0.56      0.57      1101

plot learning curve
ones 3184
zeros 9852
best estimator parameters BinaryRelevance(classifier=SVC(gamma=1, probability=True),
                require_dense=[True, True])
training data evaluation
hamming score 0.5461757823925124
hamming loss 0.18792044457443696
              precision    recall  f1-score   support

           0       0.76      0.62      0.68      2544
           1       0.90      0.35      0.51      1242
           2       0.80      0.64      0.71      2477
           3       0.82      0.30      0.44      2008

   micro avg       0.80      0.51      0.62      8271
   macro avg       0.82      0.48      0.59      8271
weighted avg       0.81      0.51      0.61      8271
 samples avg       0.57      0.51      0.53      8271

development data evaluation
hamming score 0.49849510910458994
hamming loss 0.2082392776523702
              precision    recall  f1-score   support

           0       0.74      0.59      0.66       315
           1       0.74      0.21      0.33       121
           2       0.85      0.56      0.68       400
           3       0.76      0.22      0.34       265

   micro avg       0.79      0.45      0.57      1101
   macro avg       0.77      0.40      0.50      1101
weighted avg       0.78      0.45      0.55      1101
 samples avg       0.54      0.47      0.49      1101

plot learning curve
ones 2207
zeros 10829
best estimator parameters BinaryRelevance(classifier=KNeighborsClassifier(n_neighbors=9),
                require_dense=[True, True])
training data evaluation
hamming score 0.5960441649605147
hamming loss 0.17669640245685872
              precision    recall  f1-score   support

           0       0.76      0.67      0.71      2544
           1       0.80      0.49      0.61      1242
           2       0.78      0.69      0.73      2477
           3       0.75      0.46      0.57      2008

   micro avg       0.77      0.60      0.67      8271
   macro avg       0.77      0.58      0.65      8271
weighted avg       0.77      0.60      0.67      8271
 samples avg       0.63      0.57      0.58      8271

development data evaluation
hamming score 0.4633182844243792
hamming loss 0.2316591422121896
              precision    recall  f1-score   support

           0       0.66      0.56      0.61       315
           1       0.67      0.20      0.31       121
           2       0.81      0.55      0.66       400
           3       0.57      0.22      0.32       265

   micro avg       0.71      0.44      0.54      1101
   macro avg       0.68      0.38      0.47      1101
weighted avg       0.69      0.44      0.52      1101
 samples avg       0.52      0.45      0.47      1101

plot learning curve
ones 2458
zeros 10578
best estimator parameters BinaryRelevance(classifier=LogisticRegression(C=50), require_dense=[True, True])
training data evaluation
hamming score 0.6197231159208345
hamming loss 0.16123135419713366
              precision    recall  f1-score   support

           0       0.79      0.67      0.73      2544
           1       0.86      0.57      0.69      1242
           2       0.82      0.71      0.76      2477
           3       0.76      0.46      0.57      2008

   micro avg       0.80      0.62      0.70      8271
   macro avg       0.81      0.60      0.69      8271
weighted avg       0.80      0.62      0.69      8271
 samples avg       0.65      0.60      0.61      8271

development data evaluation
hamming score 0.536117381489842
hamming loss 0.19497742663656886
              precision    recall  f1-score   support

           0       0.77      0.56      0.65       315
           1       0.76      0.29      0.42       121
           2       0.86      0.63      0.73       400
           3       0.70      0.33      0.45       265

   micro avg       0.80      0.50      0.61      1101
   macro avg       0.77      0.45      0.56      1101
weighted avg       0.79      0.50      0.60      1101
 samples avg       0.57      0.52      0.53      1101

plot learning curve
ones 2463
zeros 10573
Avg ensemble technique hamming score: 0.6695793116895778
Avg ensemble technique hamming loss: 0.14678999707516818
Avg ensemble classification matrix:               precision    recall  f1-score   support

           0       0.77      0.78      0.77      2544
           1       0.85      0.69      0.76      1242
           2       0.80      0.76      0.78      2477
           3       0.76      0.57      0.65      2008

   micro avg       0.79      0.71      0.74      8271
   macro avg       0.79      0.70      0.74      8271
weighted avg       0.79      0.71      0.74      8271
 samples avg       0.70      0.67      0.67      8271

Avg ensemble technique hamming score: 0.5451467268623025
Avg ensemble technique hamming loss: 0.1994920993227991
Avg ensemble classification matrix:               precision    recall  f1-score   support

           0       0.71      0.63      0.67       315
           1       0.77      0.30      0.43       121
           2       0.85      0.66      0.74       400
           3       0.66      0.24      0.35       265

   micro avg       0.77      0.51      0.61      1101
   macro avg       0.75      0.46      0.55      1101
weighted avg       0.76      0.51      0.59      1101
 samples avg       0.60      0.53      0.55      1101

ones 2597
zeros 10439
