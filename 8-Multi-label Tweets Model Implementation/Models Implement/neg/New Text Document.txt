best estimator parameters BinaryRelevance(classifier=GaussianNB(var_smoothing=1e-10),
                require_dense=[True, True])
training data evaluation
hamming score 0.6315126255240323
hamming loss 0.1740859900555718
              precision    recall  f1-score   support

           0       0.78      0.64      0.70      2544
           1       0.75      0.61      0.67      2602
           2       0.72      0.88      0.80      1242
           3       0.48      0.80      0.60       795
           4       0.61      0.54      0.57      2008

   micro avg       0.68      0.65      0.67      9191
   macro avg       0.67      0.69      0.67      9191
weighted avg       0.70      0.65      0.67      9191
 samples avg       0.37      0.41      0.37      9191

development data evaluation
hamming score 0.4728743416102333
hamming loss 0.2311512415349887
              precision    recall  f1-score   support

           0       0.69      0.28      0.40       315
           1       0.72      0.24      0.36       319
           2       0.66      0.27      0.39       121
           3       0.28      0.10      0.15       100
           4       0.51      0.14      0.22       265

   micro avg       0.62      0.22      0.32      1120
   macro avg       0.57      0.21      0.30      1120
weighted avg       0.61      0.22      0.32      1120
 samples avg       0.14      0.13      0.13      1120

plot learning curve
ones 1285
zeros 15010
best estimator parameters BinaryRelevance(classifier=SVC(gamma=1, probability=True),
                require_dense=[True, True])
training data evaluation
hamming score 0.5746709564200059
hamming loss 0.18876864580286634
              precision    recall  f1-score   support

           0       0.77      0.59      0.67      2544
           1       0.72      0.54      0.62      2602
           2       0.90      0.33      0.48      1242
           3       1.00      0.00      0.00       795
           4       0.84      0.29      0.43      2008

   micro avg       0.77      0.43      0.55      9191
   macro avg       0.84      0.35      0.44      9191
weighted avg       0.81      0.43      0.52      9191
 samples avg       0.34      0.28      0.29      9191

development data evaluation
hamming score 0.5390707298720843
hamming loss 0.19887133182844244
              precision    recall  f1-score   support

           0       0.75      0.49      0.59       315
           1       0.73      0.45      0.56       319
           2       0.85      0.19      0.31       121
           3       0.00      0.00      0.00       100
           4       0.78      0.14      0.24       265

   micro avg       0.75      0.32      0.45      1120
   macro avg       0.62      0.25      0.34      1120
weighted avg       0.69      0.32      0.42      1120
 samples avg       0.24      0.19      0.20      1120

plot learning curve
ones 1575
zeros 14720
best estimator parameters BinaryRelevance(classifier=KNeighborsClassifier(n_neighbors=9),
                require_dense=[True, True])
training data evaluation
hamming score 0.5988617529492054
hamming loss 0.17844398947060544
              precision    recall  f1-score   support

           0       0.76      0.62      0.68      2544
           1       0.73      0.59      0.65      2602
           2       0.81      0.47      0.60      1242
           3       0.75      0.13      0.22       795
           4       0.72      0.43      0.54      2008

   micro avg       0.75      0.51      0.60      9191
   macro avg       0.75      0.45      0.54      9191
weighted avg       0.75      0.51      0.59      9191
 samples avg       0.39      0.33      0.34      9191

development data evaluation
hamming score 0.5175884123401052
hamming loss 0.21354401805869075
              precision    recall  f1-score   support

           0       0.70      0.47      0.56       315
           1       0.64      0.42      0.51       319
           2       0.64      0.23      0.34       121
           3       0.75      0.03      0.06       100
           4       0.61      0.17      0.27       265

   micro avg       0.66      0.32      0.43      1120
   macro avg       0.67      0.27      0.35      1120
weighted avg       0.66      0.32      0.41      1120
 samples avg       0.26      0.20      0.21      1120

plot learning curve
ones 1804
zeros 14491
best estimator parameters BinaryRelevance(classifier=LogisticRegression(C=50), require_dense=[True, True])
training data evaluation
hamming score 0.6208077410548893
hamming loss 0.16788534659257093
              precision    recall  f1-score   support

           0       0.79      0.63      0.70      2544
           1       0.74      0.59      0.66      2602
           2       0.86      0.56      0.67      1242
           3       0.65      0.22      0.33       795
           4       0.77      0.43      0.56      2008

   micro avg       0.77      0.53      0.63      9191
   macro avg       0.76      0.49      0.58      9191
weighted avg       0.77      0.53      0.62      9191
 samples avg       0.40      0.35      0.36      9191

development data evaluation
hamming score 0.5503574115876599
hamming loss 0.1943566591422122
              precision    recall  f1-score   support

           0       0.79      0.48      0.60       315
           1       0.75      0.38      0.50       319
           2       0.74      0.28      0.41       121
           3       0.53      0.09      0.15       100
           4       0.71      0.28      0.40       265

   micro avg       0.75      0.35      0.47      1120
   macro avg       0.71      0.30      0.41      1120
weighted avg       0.73      0.35      0.46      1120
 samples avg       0.26      0.22      0.22      1120

plot learning curve
ones 1821
zeros 14474
Avg ensemble technique hamming score: 0.6508408891488741
Avg ensemble technique hamming loss: 0.15346592570927173
Avg ensemble classification matrix:               precision    recall  f1-score   support

           0       0.81      0.65      0.72      2544
           1       0.77      0.61      0.68      2602
           2       0.86      0.66      0.75      1242
           3       0.80      0.35      0.48       795
           4       0.74      0.50      0.60      2008

   micro avg       0.79      0.58      0.67      9191
   macro avg       0.80      0.55      0.65      9191
weighted avg       0.79      0.58      0.67      9191
 samples avg       0.40      0.38      0.37      9191

Avg ensemble technique hamming score: 0.5256207674943566
Avg ensemble technique hamming loss: 0.2054176072234763
Avg ensemble classification matrix:               precision    recall  f1-score   support

           0       0.79      0.39      0.52       315
           1       0.74      0.32      0.45       319
           2       0.78      0.29      0.42       121
           3       0.64      0.07      0.13       100
           4       0.70      0.17      0.27       265

   micro avg       0.75      0.28      0.41      1120
   macro avg       0.73      0.25      0.36      1120
weighted avg       0.74      0.28      0.40      1120
 samples avg       0.21      0.17      0.18      1120

ones 1381
zeros 14914
