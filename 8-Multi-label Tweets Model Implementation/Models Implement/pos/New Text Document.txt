best estimator parameters BinaryRelevance(classifier=GaussianNB(var_smoothing=1e-10),
                require_dense=[True, True])
training data evaluation
hamming score 0.6820464073315785
hamming loss 0.1931363946573072
              precision    recall  f1-score   support

           0       0.78      0.62      0.69      2477
           1       0.40      0.71      0.52       700
           2       0.64      0.38      0.48      1984

   micro avg       0.64      0.54      0.58      5161
   macro avg       0.61      0.57      0.56      5161
weighted avg       0.68      0.54      0.58      5161
 samples avg       0.19      0.21      0.19      5161

development data evaluation
hamming score 0.59255079006772
hamming loss 0.24454477050413845
              precision    recall  f1-score   support

           0       0.85      0.37      0.52       400
           1       0.64      0.33      0.44       132
           2       0.68      0.29      0.41       307

   micro avg       0.75      0.33      0.46       839
   macro avg       0.72      0.33      0.45       839
weighted avg       0.76      0.33      0.46       839
 samples avg       0.15      0.15      0.14       839

plot learning curve
ones 1449
zeros 8328
best estimator parameters BinaryRelevance(classifier=SVC(gamma=1, probability=True),
                require_dense=[True, True])
training data evaluation
hamming score 0.6645461635955932
hamming loss 0.18431315199376036
              precision    recall  f1-score   support

           0       0.77      0.53      0.63      2477
           1       0.84      0.04      0.07       700
           2       0.76      0.32      0.45      1984

   micro avg       0.77      0.38      0.51      5161
   macro avg       0.79      0.30      0.38      5161
weighted avg       0.78      0.38      0.49      5161
 samples avg       0.19      0.15      0.16      5161

development data evaluation
hamming score 0.5797592174567343
hamming loss 0.25319789315274643
              precision    recall  f1-score   support

           0       0.92      0.34      0.50       400
           1       0.56      0.04      0.07       132
           2       0.75      0.20      0.31       307

   micro avg       0.85      0.24      0.38       839
   macro avg       0.74      0.19      0.29       839
weighted avg       0.80      0.24      0.36       839
 samples avg       0.15      0.11      0.12       839

plot learning curve
ones 932
zeros 8845
best estimator parameters BinaryRelevance(classifier=KNeighborsClassifier(n_neighbors=9),
                require_dense=[True, True])
training data evaluation
hamming score 0.7033001852393487
hamming loss 0.16242566052451984
              precision    recall  f1-score   support

           0       0.77      0.63      0.69      2477
           1       0.72      0.27      0.39       700
           2       0.72      0.53      0.61      1984

   micro avg       0.74      0.54      0.63      5161
   macro avg       0.73      0.47      0.56      5161
weighted avg       0.74      0.54      0.62      5161
 samples avg       0.24      0.22      0.22      5161

development data evaluation
hamming score 0.5748683220466516
hamming loss 0.2562076749435666
              precision    recall  f1-score   support

           0       0.84      0.34      0.48       400
           1       0.73      0.12      0.21       132
           2       0.69      0.23      0.35       307

   micro avg       0.78      0.26      0.39       839
   macro avg       0.75      0.23      0.35       839
weighted avg       0.77      0.26      0.39       839
 samples avg       0.15      0.12      0.13       839

plot learning curve
ones 1150
zeros 8627
best estimator parameters BinaryRelevance(classifier=LogisticRegression(C=50), require_dense=[True, True])
training data evaluation
hamming score 0.6918202203373305
hamming loss 0.16754411621331775
              precision    recall  f1-score   support

           0       0.77      0.61      0.68      2477
           1       0.74      0.33      0.46       700
           2       0.72      0.43      0.53      1984

   micro avg       0.75      0.50      0.60      5161
   macro avg       0.74      0.46      0.56      5161
weighted avg       0.74      0.50      0.60      5161
 samples avg       0.23      0.20      0.21      5161

development data evaluation
hamming score 0.6051542513167795
hamming loss 0.2343867569601204
              precision    recall  f1-score   support

           0       0.88      0.42      0.57       400
           1       0.76      0.22      0.34       132
           2       0.76      0.23      0.36       307

   micro avg       0.83      0.32      0.46       839
   macro avg       0.80      0.29      0.42       839
weighted avg       0.82      0.32      0.46       839
 samples avg       0.19      0.15      0.16       839

plot learning curve
ones 1267
zeros 8510
Avg ensemble technique hamming score: 0.7037632836111924
Avg ensemble technique hamming loss: 0.16340060446524324
Avg ensemble classification matrix:               precision    recall  f1-score   support

           0       0.81      0.62      0.70      2477
           1       0.68      0.43      0.53       700
           2       0.72      0.40      0.51      1984

   micro avg       0.76      0.51      0.61      5161
   macro avg       0.73      0.48      0.58      5161
weighted avg       0.76      0.51      0.61      5161
 samples avg       0.22      0.20      0.20      5161

Avg ensemble technique hamming score: 0.5966892400300978
Avg ensemble technique hamming loss: 0.24078254326561324
Avg ensemble classification matrix:               precision    recall  f1-score   support

           0       0.90      0.36      0.52       400
           1       0.78      0.27      0.40       132
           2       0.71      0.24      0.36       307

   micro avg       0.82      0.31      0.44       839
   macro avg       0.80      0.29      0.43       839
weighted avg       0.81      0.31      0.44       839
 samples avg       0.15      0.14      0.14       839

ones 1211
zeros 8566